---
title: "Uploads"
description: "Upload & store blobs of data."
sidebarTitle: Overview
---

import { H2, Separator } from "/snippets/intro.mdx";

<Tabs>
<Tab title="Metadata">

<p>
  <span style={{ display: 'inline-block', width: '26px' }}><Icon icon="git-alt"/></span>
  <span>[Source Code](https://github.com/rivet-gg/opengb-modules/tree/main/modules/uploads)</span>
</p>



<p>
  <span style={{ display: 'inline-block', width: '26px' }}><Icon icon="user"/></span>
  <span>[rivet-gg](https://github.com/rivet-gg), [Blckbrry-Pi](https://github.com/Blckbrry-Pi), [NathanFlurry](https://github.com/NathanFlurry)</span>
</p>



<p>
  <span style={{ display: 'inline-block', width: '26px' }}><Icon icon="square-info"/></span>
  <span>Stable</span>
</p>



<p>
  <span style={{ display: 'inline-block', width: '26px' }}><Icon icon="file-certificate"/></span>
  <span>Apache 2.0</span>
</p>



<p>
  <span style={{ display: 'inline-block', width: '26px' }}><Icon icon="database"/></span>
  <span>Includes Database</span>
</p>



</Tab>

<Tab title="Install">
Run the following command in your project directory:

```bash
opengb module add uploads
```

Or add the module `uploads` to your `backend.json`.
</Tab>

<Tab title="5 Scripts">
**Public**

_No public scripts._

**Internal** 


- **[Complete Upload](/modules/uploads/scripts/complete)** (`complete`) Alert the module that the upload has been completed

- **[Delete Upload](/modules/uploads/scripts/delete)** (`delete`) Removes the upload and deletes the files from the bucket

- **[Fetch Public File URLs](/modules/uploads/scripts/fetch_public_file_urls)** (`fetch_public_file_urls`) Returns public presigned URLs for specified files in an upload

- **[Fetch Upload Metadata](/modules/uploads/scripts/fetch)** (`fetch`) Fetch the metadata (including contained files) for specified upload IDs

- **[Prepare Upload](/modules/uploads/scripts/prepare)** (`prepare`) Prepare an upload batch for data transfer

</Tab>


<Tab title="9 Errors">

- **Combined Size Limit Exceeded** (`size_limit_exceeded`) There is a maximum total size per upload (see config)


- **Duplicate Paths Provided** (`duplicate_paths`) An upload cannot contain 2 files with the same paths (see `cause` for offending paths)


- **Multipart Upload Completion Failure** (`multipart_upload_completion_fail`) The multipart upload failed to complete (see `cause` for more information)


- **No Files Provided** (`no_files`) An upload must have at least 1 file


- **Possibility Of Too Many Chunks** (`too_many_chunks`) AWS S3 has a limit on the number of parts that can be uploaded in a
multipart upload. This limit is 10,000 parts. If the number of chunks
required to upload the maximum multipart upload size exceeds this limit,
any operation will preemptively throw this error.



- **S3 Not Configured** (`s3_not_configured`) The S3 bucket is not configured (missing env variables)


- **Too Many Files Provided** (`too_many_files`) There is a limit to how many files can be put into a single upload (see config)


- **Upload Already completed** (`upload_already_completed`) \`complete\` was already called on this upload


- **Upload Not Found** (`upload_not_found`) The provided upload ID didn't match any known existing uploads

</Tab>


<Tab title="0 Dependencies">

_No dependencies_

</Tab>
</Tabs>

---


